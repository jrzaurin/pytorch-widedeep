{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment there are 5 transformer-based algorithms available. \n",
    "\n",
    "Here are examples of how to use them\n",
    "\n",
    "Perhaps the main comment is that when using transformer-based models, the data preparation is a bit different than in other models. Therefore one needs to know the set up at pre-processing stage. \n",
    "\n",
    "Let's have a look, starting with the `TabTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javier/.pyenv/versions/3.7.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.training import Trainer\n",
    "from pytorch_widedeep.models import TabTransformer, SAINT, FTTransformer, TabFastFormer, TabPerceiver, WideDeep\n",
    "from pytorch_widedeep.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/adult/adult.csv.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education      marital_status  \\\n",
       "0   25    Private  226802          11th       Never-married   \n",
       "1   38    Private   89814       HS-grad  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital_gain  capital_loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours_per_week native_country  target  \n",
       "0              40  United-States       0  \n",
       "1              50  United-States       0  \n",
       "2              40  United-States       1  \n",
       "3              40  United-States       1  \n",
       "4              30  United-States       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For convenience, we'll replace '-' with '_'\n",
    "df.columns = [c.replace(\"-\", \"_\") for c in df.columns]\n",
    "#binary target\n",
    "df['target'] = (df[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "df.drop([\"income\", \"educational_num\"], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, cont_cols = [], []\n",
    "for col in df.columns:\n",
    "    # 50 is just a random number I choose here for this example\n",
    "    if df[col].dtype == \"O\" or df[col].nunique() < 50 and col != \"target\":\n",
    "        cat_cols.append(col)\n",
    "    elif col != \"target\":        \n",
    "        cont_cols.append(col)\n",
    "target_col = \"target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Standard\" `TabTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[target_col].values\n",
    "\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_cols, \n",
    "                                   continuous_cols=cont_cols, \n",
    "                                   for_transformer=True\n",
    "                                  )\n",
    "X_tab = tab_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here all categorical columns will be encoded as 32 dim embeddings, then passed through the transformer \n",
    "# blocks, concatenated with the continuous and finally through an MLP\n",
    "tab_transformer = TabTransformer(column_idx=tab_preprocessor.column_idx,\n",
    "                                 embed_input=tab_preprocessor.embeddings_input,\n",
    "                                 continuous_cols=tab_preprocessor.continuous_cols, \n",
    "                                 cont_norm_layer=\"batchnorm\", \n",
    "                                 n_blocks=4, n_heads=4 \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (cat_and_cont_embed): CatAndContEmbeddings(\n",
       "    (cat_embed): CategoricalEmbeddings(\n",
       "      (embed): Embedding(103, 32, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (cont_norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (transformer_block0): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_block1): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_block2): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_block3): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=261, out_features=1044, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=1044, out_features=522, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(deeptabular=tab_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, objective='binary', metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:14<00:00, 10.56it/s, loss=0.356, metrics={'acc': 0.8321}]\n",
      "valid: 100%|██████████| 39/39 [00:01<00:00, 36.52it/s, loss=0.336, metrics={'acc': 0.8465}]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=1, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also choose to use the `FT-Transformer`, where continuous cols are also represented by \"Embeddings\", via a 1 layer MLP (with or without activation function). When using the `FT-Transformer` we can choose to use the `[CLS]` token as a pooling method or concatenate the output from the transformer blocks, as we did before. Let's use here the `[CLS]` token. Also note that under the hood, the `FT-Transformer` uses Linear Attention. See [Linformer: Self-Attention with Linear Complexity](https://arxiv.org/pdf/2006.04768.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_cols, \n",
    "                                   continuous_cols=cont_cols, \n",
    "                                   for_transformer=True,\n",
    "                                   with_cls_token=True\n",
    "                                  )\n",
    "X_tab = tab_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_transformer = FTTransformer(column_idx=tab_preprocessor.column_idx,\n",
    "                                embed_input=tab_preprocessor.embeddings_input,\n",
    "                                continuous_cols=tab_preprocessor.continuous_cols, \n",
    "                                n_blocks=3, n_heads=6, input_dim=36\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTTransformer(\n",
       "  (cat_and_cont_embed): CatAndContEmbeddings(\n",
       "    (cat_embed): CategoricalEmbeddings(\n",
       "      (embed): Embedding(104, 36, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (cont_norm): Identity()\n",
       "    (cont_embed): ContinuousEmbeddings()\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (fttransformer_block0): FTTransformerEncoder(\n",
       "      (attn): LinearAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (qkv_proj): Linear(in_features=36, out_features=108, bias=False)\n",
       "        (out_proj): Linear(in_features=36, out_features=36, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=36, out_features=94, bias=True)\n",
       "        (w_2): Linear(in_features=47, out_features=36, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): REGLU()\n",
       "      )\n",
       "      (attn_normadd): NormAdd(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_normadd): NormAdd(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fttransformer_block1): FTTransformerEncoder(\n",
       "      (attn): LinearAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (qkv_proj): Linear(in_features=36, out_features=108, bias=False)\n",
       "        (out_proj): Linear(in_features=36, out_features=36, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=36, out_features=94, bias=True)\n",
       "        (w_2): Linear(in_features=47, out_features=36, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): REGLU()\n",
       "      )\n",
       "      (attn_normadd): NormAdd(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_normadd): NormAdd(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fttransformer_block2): FTTransformerEncoder(\n",
       "      (attn): LinearAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (qkv_proj): Linear(in_features=36, out_features=108, bias=False)\n",
       "        (out_proj): Linear(in_features=36, out_features=36, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=36, out_features=94, bias=True)\n",
       "        (w_2): Linear(in_features=47, out_features=36, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): REGLU()\n",
       "      )\n",
       "      (attn_normadd): NormAdd(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_normadd): NormAdd(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(deeptabular=ft_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, objective='binary', metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:15<00:00,  9.62it/s, loss=0.382, metrics={'acc': 0.8167}]\n",
      "valid: 100%|██████████| 39/39 [00:01<00:00, 28.84it/s, loss=0.317, metrics={'acc': 0.8566}]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=1, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can choose to use SAINT, with its inter-sample attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saint = SAINT(column_idx=tab_preprocessor.column_idx,\n",
    "              embed_input=tab_preprocessor.embeddings_input,\n",
    "              continuous_cols=tab_preprocessor.continuous_cols, \n",
    "              transformer_activation=\"geglu\",\n",
    "              n_blocks=2, n_heads=4, \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (cat_and_cont_embed): CatAndContEmbeddings(\n",
       "    (cat_embed): CategoricalEmbeddings(\n",
       "      (embed): Embedding(104, 32, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (cont_norm): Identity()\n",
       "    (cont_embed): ContinuousEmbeddings()\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (saint_block0): SaintEncoder(\n",
       "      (col_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (col_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (activation): GEGLU()\n",
       "      )\n",
       "      (col_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (col_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_proj): Linear(in_features=448, out_features=448, bias=False)\n",
       "        (kv_proj): Linear(in_features=448, out_features=896, bias=False)\n",
       "        (out_proj): Linear(in_features=448, out_features=448, bias=False)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=448, out_features=3584, bias=True)\n",
       "        (w_2): Linear(in_features=1792, out_features=448, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (activation): GEGLU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (saint_block1): SaintEncoder(\n",
       "      (col_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (col_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (activation): GEGLU()\n",
       "      )\n",
       "      (col_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (col_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_proj): Linear(in_features=448, out_features=448, bias=False)\n",
       "        (kv_proj): Linear(in_features=448, out_features=896, bias=False)\n",
       "        (out_proj): Linear(in_features=448, out_features=448, bias=False)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=448, out_features=3584, bias=True)\n",
       "        (w_2): Linear(in_features=1792, out_features=448, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (activation): GEGLU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 306/306 [00:47<00:00,  6.42it/s, loss=0.377, metrics={'acc': 0.8224}]\n",
      "valid: 100%|██████████| 77/77 [00:02<00:00, 32.20it/s, loss=0.338, metrics={'acc': 0.8529}]\n"
     ]
    }
   ],
   "source": [
    "model = WideDeep(deeptabular=saint)\n",
    "trainer = Trainer(model, objective='binary', metrics=[Accuracy])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=1, batch_size=128, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous models have all been published. The following two are adaptations of existing Transformer models for tabular data and by the time I am writing this they are only available in this library. If I have the time I will write a post about their implementation. Nonetheless, all the details can be found in the [docs](https://pytorch-widedeep.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "The first one is an adaptation of [Fastformer: Additive Attention Can Be All You Need](https://arxiv.org/pdf/2108.09084.pdf). I have mixed feelings towards that paper, that I will not be covering here, but you can go and watch [Yannic's video](https://www.youtube.com/watch?v=qgUegkefocg&t=1s) since most of my opinions are also explained there. Nonetheless, the reason to bring this model to the library is because in essence, the `FastFormer` is an \"elaborated MLP\" with an \"interesting\" attention aggregated attention mechanism. Since MLPs work really well for tabular data compared to other, more complex models, why not add it to the library.  \n",
    "\n",
    "To use it, just follow the same routine as with any other transformer-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabfastformer = TabFastFormer(column_idx=tab_preprocessor.column_idx,\n",
    "              embed_input=tab_preprocessor.embeddings_input,\n",
    "              continuous_cols=tab_preprocessor.continuous_cols, \n",
    "              n_blocks=2, n_heads=4,             \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabFastFormer(\n",
       "  (cat_and_cont_embed): CatAndContEmbeddings(\n",
       "    (cat_embed): CategoricalEmbeddings(\n",
       "      (embed): Embedding(104, 32, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (cont_norm): Identity()\n",
       "    (cont_embed): ContinuousEmbeddings()\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (fastformer_block0): FastFormerEncoder(\n",
       "      (attn): AdditiveAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (W_q): Linear(in_features=8, out_features=1, bias=False)\n",
       "        (W_k): Linear(in_features=8, out_features=1, bias=False)\n",
       "        (r_out): Linear(in_features=8, out_features=8, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fastformer_block1): FastFormerEncoder(\n",
       "      (attn): AdditiveAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (W_q): Linear(in_features=8, out_features=1, bias=False)\n",
       "        (W_k): Linear(in_features=8, out_features=1, bias=False)\n",
       "        (r_out): Linear(in_features=8, out_features=8, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabfastformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:10<00:00, 14.58it/s, loss=0.46, metrics={'acc': 0.7867}] \n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 48.19it/s, loss=0.342, metrics={'acc': 0.8443}]\n"
     ]
    }
   ],
   "source": [
    "model = WideDeep(deeptabular=tabfastformer)\n",
    "trainer = Trainer(model, objective='binary', metrics=[Accuracy])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=1, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the last of the transformer-based models that are currently available in the library is DeepMind's [Perceiver](https://arxiv.org/pdf/2103.03206.pdf). The reason to add this model to the library is the following. The Perceiver is meant to be an architecture agnostic of the nature of the input data, i.e. it is meant to work with audio, images, text...So why not tabular, right? \n",
    "\n",
    "To use it...you guessed right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_cols, \n",
    "                                   continuous_cols=cont_cols, \n",
    "                                   for_transformer=True,\n",
    "                                  )\n",
    "X_tab = tab_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabperceiver = TabPerceiver(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    embed_input=tab_preprocessor.embeddings_input,\n",
    "    continuous_cols=tab_preprocessor.continuous_cols, \n",
    "    n_perceiver_blocks=1, \n",
    "    n_latent_blocks=3, \n",
    "    n_latent_heads=2, \n",
    "    n_latents=6,\n",
    "    latent_dim=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:16<00:00,  9.45it/s, loss=0.4, metrics={'acc': 0.81}]    \n",
      "valid: 100%|██████████| 39/39 [00:01<00:00, 37.95it/s, loss=0.323, metrics={'acc': 0.8542}]\n"
     ]
    }
   ],
   "source": [
    "model = WideDeep(deeptabular=tabperceiver)\n",
    "trainer = Trainer(model, objective='binary', metrics=[Accuracy])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=1, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final comment is that all transformer-based models have the option of using the so called \"Shared Embeddings\". The idea behind the shared embeddings is explained in the original TabTransformer paper and also here in this [post](https://jrzaurin.github.io/infinitoml/2021/02/18/pytorch-widedeep_iii.html).\n",
    "\n",
    "For transformer-based models this implies a bit of a different data preparation process since each column will be encoded individually (programmatically is way easier to implement) and the use of shared embeddings needs to be specified at preprocessing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_cols, \n",
    "                                   continuous_cols=cont_cols, \n",
    "                                   for_transformer=True,\n",
    "                                   shared_embed=True,\n",
    "                                   with_cls_token=True\n",
    "                                  )\n",
    "X_tab = tab_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_transformer = TabTransformer(column_idx=tab_preprocessor.column_idx,\n",
    "                                embed_input=tab_preprocessor.embeddings_input,\n",
    "                                continuous_cols=tab_preprocessor.continuous_cols, \n",
    "                                embed_continuous=True,\n",
    "                                embed_continuous_activation=None,       \n",
    "                                shared_embed=True,  \n",
    "                                cont_norm_layer=\"batchnorm\", \n",
    "                                n_blocks=4, n_heads=4 \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (cat_and_cont_embed): CatAndContEmbeddings(\n",
       "    (cat_embed): CategoricalEmbeddings(\n",
       "      (embed): ModuleDict(\n",
       "        (emb_layer_cls_token): SharedEmbeddings(\n",
       "          (embed): Embedding(1, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_education): SharedEmbeddings(\n",
       "          (embed): Embedding(17, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_gender): SharedEmbeddings(\n",
       "          (embed): Embedding(3, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_marital_status): SharedEmbeddings(\n",
       "          (embed): Embedding(8, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_native_country): SharedEmbeddings(\n",
       "          (embed): Embedding(43, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_occupation): SharedEmbeddings(\n",
       "          (embed): Embedding(16, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_race): SharedEmbeddings(\n",
       "          (embed): Embedding(6, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_relationship): SharedEmbeddings(\n",
       "          (embed): Embedding(7, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (emb_layer_workclass): SharedEmbeddings(\n",
       "          (embed): Embedding(10, 32, padding_idx=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cont_norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cont_embed): ContinuousEmbeddings()\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (transformer_block0): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_block1): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_block2): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_block3): TransformerEncoder(\n",
       "      (attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (kv_proj): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:20<00:00,  7.62it/s, loss=0.4, metrics={'acc': 0.8061}]  \n",
      "valid: 100%|██████████| 39/39 [00:01<00:00, 30.53it/s, loss=0.324, metrics={'acc': 0.8551}]\n"
     ]
    }
   ],
   "source": [
    "model = WideDeep(deeptabular=ft_transformer)\n",
    "trainer = Trainer(model, objective='binary', metrics=[Accuracy])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=1, batch_size=256, val_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
