{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Binary Classification with defaults\n",
    "\n",
    "In this notebook we will train a Wide and Deep model and simply a \"Deep\" model using the well known adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.training import Trainer\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep, TabNet\n",
    "from pytorch_widedeep.metrics import Accuracy, Precision\n",
    "from pytorch_widedeep.datasets import load_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_adult(as_frame=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational_num      marital_status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital_gain  capital_loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours_per_week native_country  income_label  \n",
       "0              40  United-States             0  \n",
       "1              50  United-States             0  \n",
       "2              40  United-States             1  \n",
       "3              40  United-States             1  \n",
       "4              30  United-States             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For convenience, we'll replace '-' with '_'\n",
    "df.columns = [c.replace(\"-\", \"_\") for c in df.columns]\n",
    "# binary target\n",
    "df[\"income_label\"] = (df[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "df.drop(\"income\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"fnlwgt\", \"educational_num\"], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Define wide, crossed and deep tabular columns\n",
    "wide_cols = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"native_country\",\n",
    "]\n",
    "crossed_cols = [(\"education\", \"occupation\"), (\"native_country\", \"occupation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_embed_cols = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"native_country\",\n",
    "]\n",
    "continuous_cols = [\"age\", \"hours_per_week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'native_country']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_embed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET\n",
    "target_col = \"income_label\"\n",
    "target = df[target_col].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see what the preprocessors do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # wide_preprocessor has an attribute called encoding_dict with the encoding dictionary\n",
    "# wide_preprocessor.encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeptabular\n",
    "tab_preprocessor = TabPreprocessor(\n",
    "    embed_cols=cat_embed_cols, continuous_cols=continuous_cols\n",
    ")\n",
    "X_tab = tab_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('workclass', 9, 5),\n",
       " ('education', 16, 8),\n",
       " ('marital_status', 7, 5),\n",
       " ('occupation', 15, 7),\n",
       " ('relationship', 6, 4),\n",
       " ('race', 5, 4),\n",
       " ('gender', 2, 2),\n",
       " ('capital_gain', 123, 24),\n",
       " ('capital_loss', 99, 21),\n",
       " ('native_country', 42, 13)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the docs to understand the useful attributes that the tab_preprocessor has. For example,\n",
    "# as well as an encoding dictionary, tab_preprocessor has an attribute called cat_embed_input\n",
    "# that specifies the categortical columns that will be represented as embeddings, the number\n",
    "# of different categories per feature, and the dimension of the embeddings as defined by some\n",
    "# of the internal rules of thumb that the preprocessor has (have a look to the docs)\n",
    "tab_preprocessor.cat_embed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  10  26 ...  61 103 328]\n",
      " [  1  11  27 ...  61 104 329]\n",
      " [  2  12  27 ...  61 105 330]\n",
      " ...\n",
      " [  1  11  28 ...  61 115 335]\n",
      " [  1  11  26 ...  61 115 335]\n",
      " [  7  11  27 ...  61 127 336]]\n",
      "(48842, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(X_wide)\n",
    "print(X_wide.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...  1.         -0.99512893\n",
      "  -0.03408696]\n",
      " [ 1.          2.          2.         ...  1.         -0.04694151\n",
      "   0.77292975]\n",
      " [ 2.          3.          2.         ...  1.         -0.77631645\n",
      "  -0.03408696]\n",
      " ...\n",
      " [ 1.          2.          3.         ...  1.          1.41180837\n",
      "  -0.03408696]\n",
      " [ 1.          2.          1.         ...  1.         -1.21394141\n",
      "  -1.64812038]\n",
      " [ 7.          2.          2.         ...  1.          0.97418341\n",
      "  -0.03408696]]\n",
      "(48842, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_tab)\n",
    "print(X_tab.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "wide = Wide(input_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "model = TabNet(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    cat_embed_input=tab_preprocessor.cat_embed_input,\n",
    "    cat_embed_dropout=0.1,\n",
    "    continuous_cols=continuous_cols,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first find out how a linear model performs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'./checkpoints/{args.model}/{args.country}/chkp',\n",
    "    save_best_only=True,\n",
    "    max_save=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    LRHistory(n_epochs=10),\n",
    "    EarlyStopping(patience=10),\n",
    "    model_checkpoint,\n",
    "]\n",
    "metrics = [auroc]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=\"binary\",\n",
    "    optimizers=torch.optim.Adam(model.parameters(), lr=0.01),\n",
    "    callbacks=callbacks,\n",
    "    metrics=metrics,\n",
    "    verbose=True,\n",
    "    seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/envs/pytorch_widedeep/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "tab_net_widedeep = WideDeep(deeptabular=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (deeptabular): Sequential(\n",
       "    (0): TabNet(\n",
       "      (cat_and_cont_embed): DiffSizeCatAndContEmbeddings(\n",
       "        (cat_embed): DiffSizeCatEmbeddings(\n",
       "          (embed_layers): ModuleDict(\n",
       "            (emb_layer_workclass): Embedding(10, 5, padding_idx=0)\n",
       "            (emb_layer_education): Embedding(17, 8, padding_idx=0)\n",
       "            (emb_layer_marital_status): Embedding(8, 5, padding_idx=0)\n",
       "            (emb_layer_occupation): Embedding(16, 7, padding_idx=0)\n",
       "            (emb_layer_relationship): Embedding(7, 4, padding_idx=0)\n",
       "            (emb_layer_race): Embedding(6, 4, padding_idx=0)\n",
       "            (emb_layer_gender): Embedding(3, 2, padding_idx=0)\n",
       "            (emb_layer_capital_gain): Embedding(124, 24, padding_idx=0)\n",
       "            (emb_layer_capital_loss): Embedding(100, 21, padding_idx=0)\n",
       "            (emb_layer_native_country): Embedding(43, 13, padding_idx=0)\n",
       "          )\n",
       "          (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cont_norm): Identity()\n",
       "      )\n",
       "      (encoder): TabNetEncoder(\n",
       "        (initial_bn): BatchNorm1d(95, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (initial_splitter): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=95, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (dp): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (dp): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (step_dependent): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (dp): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (dp): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (feat_transformers): ModuleList(\n",
       "          (0): FeatTransformer(\n",
       "            (shared): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=95, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (step_dependent): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): FeatTransformer(\n",
       "            (shared): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=95, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (step_dependent): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): FeatTransformer(\n",
       "            (shared): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=95, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (step_dependent): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                  (dp): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attn_transformers): ModuleList(\n",
       "          (0): AttentiveTransformer(\n",
       "            (fc): Linear(in_features=8, out_features=95, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(95, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (mask): Sparsemax()\n",
       "          )\n",
       "          (1): AttentiveTransformer(\n",
       "            (fc): Linear(in_features=8, out_features=95, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(95, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (mask): Sparsemax()\n",
       "          )\n",
       "          (2): AttentiveTransformer(\n",
       "            (fc): Linear(in_features=8, out_features=95, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(95, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (mask): Sparsemax()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TabNetPredLayer(\n",
       "      (pred_layer): Linear(in_features=8, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_net_widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 96.66it/s, loss=0.418, metrics={'acc': 0.8024, 'prec': 0.6664}]\n",
      "valid: 100%|██████████████████████████████████████| 77/77 [00:00<00:00, 168.33it/s, loss=0.355, metrics={'acc': 0.8317, 'prec': 0.8402}]\n",
      "epoch 2: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 98.26it/s, loss=0.376, metrics={'acc': 0.8222, 'prec': 0.7253}]\n",
      "valid: 100%|██████████████████████████████████████| 77/77 [00:00<00:00, 172.84it/s, loss=0.338, metrics={'acc': 0.8546, 'prec': 0.7901}]\n",
      "epoch 3: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 99.54it/s, loss=0.362, metrics={'acc': 0.8305, 'prec': 0.7402}]\n",
      "valid: 100%|████████████████████████████████████████| 77/77 [00:00<00:00, 173.62it/s, loss=0.327, metrics={'acc': 0.863, 'prec': 0.761}]\n",
      "epoch 4: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 97.46it/s, loss=0.351, metrics={'acc': 0.8373, 'prec': 0.7478}]\n",
      "valid: 100%|██████████████████████████████████████| 77/77 [00:00<00:00, 169.21it/s, loss=0.323, metrics={'acc': 0.8651, 'prec': 0.7673}]\n"
     ]
    }
   ],
   "source": [
    "tab_trainer.fit(X_tab=X_tab, target=target, n_epochs=4, batch_size=128, val_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result I ever obtained with `LightGBM` on this dataset is 0.8782...so we are pretty close.\n",
    "\n",
    "Let's combine the `wide` and `tab_mlp` components see if it helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 87.74it/s, loss=0.511, metrics={'acc': 0.7659, 'prec': 0.5139}]\n",
      "valid: 100%|███████████████████████████████████████| 77/77 [00:00<00:00, 144.96it/s, loss=0.406, metrics={'acc': 0.795, 'prec': 0.5659}]\n",
      "epoch 2: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 90.59it/s, loss=0.405, metrics={'acc': 0.8114, 'prec': 0.6346}]\n",
      "valid: 100%|██████████████████████████████████████| 77/77 [00:00<00:00, 148.66it/s, loss=0.371, metrics={'acc': 0.8189, 'prec': 0.6099}]\n",
      "epoch 3: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 89.61it/s, loss=0.368, metrics={'acc': 0.8298, 'prec': 0.6874}]\n",
      "valid: 100%|██████████████████████████████████████| 77/77 [00:00<00:00, 150.18it/s, loss=0.353, metrics={'acc': 0.8325, 'prec': 0.6342}]\n",
      "epoch 4: 100%|███████████████████████████████████| 306/306 [00:03<00:00, 88.74it/s, loss=0.348, metrics={'acc': 0.8407, 'prec': 0.7187}]\n",
      "valid: 100%|███████████████████████████████████████| 77/77 [00:00<00:00, 150.39it/s, loss=0.339, metrics={'acc': 0.8434, 'prec': 0.663}]\n"
     ]
    }
   ],
   "source": [
    "wd_trainer.fit(\n",
    "    X_wide=X_wide, X_tab=X_tab, target=target, n_epochs=4, batch_size=128, val_split=0.2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular case, the combination of both did not lead to better results that using just the tab_mlp model. \n",
    "\n",
    "Note that we have use a `TabMlp` model, but we could use any other model in the library using the same syntax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b99005fd577fa40f3cce433b2b92303885900e634b2b5344c07c59d06c8792d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
