{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE THE DATA\n",
    "\n",
    "These are the steps required to prepare the data before is passed to the *\"Wide and Deep\"* model at `wide_deep/torch_model.py`\n",
    "\n",
    "Let's first load the data and create a target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "      <th>income_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \\\n",
       "0          2174             0              40  United-States          <=50K   \n",
       "1             0             0              13  United-States          <=50K   \n",
       "2             0             0              40  United-States          <=50K   \n",
       "3             0             0              40  United-States          <=50K   \n",
       "4             0             0              40           Cuba          <=50K   \n",
       "\n",
       "   income_label  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DF = pd.read_csv('data/adult_data.csv')\n",
    "\n",
    "# Let's create a feature that will be our target for logistic classification\n",
    "DF['income_label'] = (DF[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Set the experiment\n",
    "\n",
    "We need to define the columns in the dataset that will be passed to the *\"wide-\"* and the *\"deep-side\"* of the model. For more details of what I mean by \"wide\" and \"deep\" I recommend either to read [this tutorial](https://www.tensorflow.org/tutorials/wide_and_deep), the [original paper](https://arxiv.org/pdf/1606.07792.pdf) or the demo2 in this repo. \n",
    "\n",
    "In the example below, the wide and crossed column will be passed to the wide side of the model while the embedding_cols and continuous columns will go through the deep side. \n",
    "\n",
    "We also need to state our target and the method that will be used to fit/predict that target (regression, logistic or multiclass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_cols = ['age','hours_per_week','education', 'relationship','workclass',\n",
    "             'occupation','native_country','gender']\n",
    "crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
    "embeddings_cols = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                    ('occupation',10),('native_country',12)]\n",
    "continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "target = 'income_label'\n",
    "method = 'logistic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that `embeddings_cols` is a list of tuples with two elements. These are the column name and the \"dimension of the corresponding embeddings\" (i.e. the number of embeddings per feature), so that when passed through the Deep-side education will be represented by 10 embeddings, relatioship by 8, etc.\n",
    "\n",
    "If you want to use the same number of embeddings for *all* the embedding columns you can simply include the column names and define the number of embeddings when calling to the `prepare_data` function I mention before. This function has a parameter called `def_dim` (default dimension) that will be applied to all embedding columns if no embedding dimension. The first few lines on `prepare_data` look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If embeddings_cols does not include the number of embeddings, it will be set as\n",
    "# def_dim (8)\n",
    "if len(embeddings_cols[0]) == 1:\n",
    "    emb_dim = {e:def_dim for e in embeddings_cols}\n",
    "else:\n",
    "    emb_dim = dict(embeddings_cols)\n",
    "    embeddings_cols = [emb[0] for emb in embeddings_cols]\n",
    "deep_cols = embeddings_cols+continuous_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Cross-product for binary features\n",
    "\n",
    "At explained in the original paper: *\"For binary features, a cross-product transformation (e.g.,\n",
    "`AND(gender=female, language=en))` is 1 if and only if the constituent features (`gender=female and language=en`)\n",
    "are all 1, and 0 otherwise\"*. Here, this is implemented by combining the features into a new feature and one-hot encoded it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.array(DF[target])\n",
    "# We copy the original dataset so we do not mutate it\n",
    "df_tmp = DF.copy()[list(set(wide_cols + deep_cols))]\n",
    "\n",
    "# Build the crossed columns\n",
    "crossed_columns = []\n",
    "for cols in crossed_cols:\n",
    "    colname = '_'.join(cols)\n",
    "    df_tmp[colname] = df_tmp[cols].apply(lambda x: '-'.join(x), axis=1)\n",
    "    crossed_columns.append(colname)\n",
    "\n",
    "# Extract the categorical column names that can be one hot encoded later\n",
    "categorical_columns = list(df_tmp.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to one of the \"crossed features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bachelors-Adm-clerical\n",
       "1    Bachelors-Exec-managerial\n",
       "2    HS-grad-Handlers-cleaners\n",
       "3       11th-Handlers-cleaners\n",
       "4     Bachelors-Prof-specialty\n",
       "Name: education_occupation, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp['education_occupation'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we one-hot encode this feature later, it will be only 1 if and only if the two constituent features are 1. In other words, the level `Bachelors-Adm-clerical` of the `education_occupation` feature will be 1 if and only if for that particular observation `education=Bachelors` AND `occupation=Adm-clerical`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Label-encoding and splitting the dataframe into wide and deep.\n",
    "\n",
    "We first encode the dataframe and keep a dictionary of the encodings for those columns that will be represented as embeddings (for the remaining ones is unneccesary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_encode(df, cols=None):\n",
    "    \"\"\"\n",
    "    Helper function to label-encode some features of a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    --------\n",
    "    df  (pd.Dataframe)\n",
    "    cols (list): optional - columns to be label-encoded\n",
    "\n",
    "    Returns:\n",
    "    ________\n",
    "    val_to_idx (dict) : Dictionary of dictionaries with useful information about\n",
    "    the encoding mapping\n",
    "    df (pd.Dataframe): mutated df with Label-encoded features.\n",
    "    \"\"\"\n",
    "\n",
    "    if cols == None:\n",
    "        cols = list(df.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    val_types = dict()\n",
    "    for c in cols:\n",
    "        val_types[c] = df[c].unique()\n",
    "\n",
    "    val_to_idx = dict()\n",
    "    for k, v in val_types.iteritems():\n",
    "        val_to_idx[k] = {o: i for i, o in enumerate(val_types[k])}\n",
    "\n",
    "    for k, v in val_to_idx.iteritems():\n",
    "        df[k] = df[k].apply(lambda x: v[x])\n",
    "\n",
    "    return val_to_idx, df\n",
    "\n",
    "# Encode the dataframe and get the encoding Dictionary only for the\n",
    "# deep_cols (for the wide_cols is uneccessary)\n",
    "encoding_dict,df_tmp = label_encode(df_tmp)\n",
    "encoding_dict = {k:encoding_dict[k] for k in encoding_dict if k in deep_cols}\n",
    "embeddings_input = []\n",
    "for k,v in encoding_dict.iteritems():\n",
    "    embeddings_input.append((k, len(v), emb_dim[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the data frame into the wide and deep data frames and keep the index of the deep column. This information will be used later since we will slice the tensors based on index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# select the deep_cols and get the column index that will be use later\n",
    "# to slice the tensors\n",
    "df_deep = df_tmp[deep_cols]\n",
    "deep_column_idx = {k:v for v,k in enumerate(df_deep.columns)}\n",
    "\n",
    "# The continous columns will be concatenated with the embeddings, so you\n",
    "# might want to normalize them first\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "for cc in continuous_cols:\n",
    "    df_deep[cc]  = scaler.fit_transform(df_deep[cc].values.reshape(-1,1))\n",
    "\n",
    "df_wide = df_tmp[wide_cols+crossed_columns]\n",
    "del(df_tmp)\n",
    "\n",
    "dummy_cols = [c for c in wide_cols+crossed_columns if c in categorical_columns]\n",
    "df_wide = pd.get_dummies(df_wide, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-Train/Test split and build the output dictionary\n",
    "\n",
    "I think the code here is self explanatory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "\n",
    "seed = 1981\n",
    "X_train_deep, X_test_deep = train_test_split(df_deep.values, test_size=0.3, random_state=seed)\n",
    "X_train_wide, X_test_wide = train_test_split(df_wide.values, test_size=0.3, random_state=seed)\n",
    "y_train, y_test = train_test_split(Y, test_size=0.3, random_state=1981)\n",
    "\n",
    "# Building the output dictionary\n",
    "wd_dataset = dict()\n",
    "train_dataset = namedtuple('train_dataset', 'wide, deep, labels')\n",
    "test_dataset  = namedtuple('test_dataset' , 'wide, deep, labels')\n",
    "wd_dataset['train_dataset'] = train_dataset(X_train_wide, X_train_deep, y_train)\n",
    "wd_dataset['test_dataset']  = test_dataset(X_test_wide, X_test_deep, y_test)\n",
    "wd_dataset['embeddings_input']  = embeddings_input\n",
    "wd_dataset['deep_column_idx'] = deep_column_idx\n",
    "wd_dataset['encoding_dict'] = encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset(wide=array([[46, 50,  0, ...,  0,  0,  0],\n",
      "       [32, 45,  1, ...,  0,  0,  0],\n",
      "       [30, 30,  0, ...,  0,  0,  0],\n",
      "       ..., \n",
      "       [40, 40,  0, ...,  0,  0,  0],\n",
      "       [45, 37,  1, ...,  0,  0,  0],\n",
      "       [40, 45,  1, ...,  0,  0,  0]]), deep=array([[ 3.        ,  1.        ,  6.        , ...,  0.        ,\n",
      "         0.53655844,  0.77292975],\n",
      "       [ 0.        ,  0.        ,  2.        , ...,  0.        ,\n",
      "        -0.48456647,  0.36942139],\n",
      "       [ 1.        ,  4.        ,  2.        , ...,  0.        ,\n",
      "        -0.63044146, -0.84110367],\n",
      "       ..., \n",
      "       [ 1.        ,  0.        ,  2.        , ...,  0.        ,\n",
      "         0.09893348, -0.03408696],\n",
      "       [ 0.        ,  1.        ,  2.        , ...,  0.        ,\n",
      "         0.46362095, -0.27619198],\n",
      "       [ 0.        ,  1.        ,  2.        , ...,  0.        ,\n",
      "         0.09893348,  0.36942139]]), labels=array([1, 0, 0, ..., 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "print(wd_dataset['train_dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('workclass', 9, 10), ('education', 16, 10), ('native_country', 42, 12), ('relationship', 6, 8), ('occupation', 15, 10)]\n"
     ]
    }
   ],
   "source": [
    "print(wd_dataset['embeddings_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hours_per_week': 6, 'native_country': 4, 'relationship': 1, 'age': 5, 'workclass': 2, 'education': 0, 'occupation': 3}\n"
     ]
    }
   ],
   "source": [
    "print(wd_dataset['deep_column_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education': {'10th': 12,\n",
       "  '11th': 2,\n",
       "  '12th': 15,\n",
       "  '1st-4th': 13,\n",
       "  '5th-6th': 11,\n",
       "  '7th-8th': 8,\n",
       "  '9th': 4,\n",
       "  'Assoc-acdm': 6,\n",
       "  'Assoc-voc': 7,\n",
       "  'Bachelors': 0,\n",
       "  'Doctorate': 9,\n",
       "  'HS-grad': 1,\n",
       "  'Masters': 3,\n",
       "  'Preschool': 14,\n",
       "  'Prof-school': 10,\n",
       "  'Some-college': 5},\n",
       " 'native_country': {'?': 4,\n",
       "  'Cambodia': 17,\n",
       "  'Canada': 10,\n",
       "  'China': 28,\n",
       "  'Columbia': 16,\n",
       "  'Cuba': 1,\n",
       "  'Dominican-Republic': 24,\n",
       "  'Ecuador': 19,\n",
       "  'El-Salvador': 25,\n",
       "  'England': 9,\n",
       "  'France': 26,\n",
       "  'Germany': 11,\n",
       "  'Greece': 35,\n",
       "  'Guatemala': 27,\n",
       "  'Haiti': 22,\n",
       "  'Holand-Netherlands': 41,\n",
       "  'Honduras': 8,\n",
       "  'Hong': 38,\n",
       "  'Hungary': 40,\n",
       "  'India': 3,\n",
       "  'Iran': 12,\n",
       "  'Ireland': 39,\n",
       "  'Italy': 14,\n",
       "  'Jamaica': 2,\n",
       "  'Japan': 29,\n",
       "  'Laos': 20,\n",
       "  'Mexico': 5,\n",
       "  'Nicaragua': 36,\n",
       "  'Outlying-US(Guam-USVI-etc)': 32,\n",
       "  'Peru': 31,\n",
       "  'Philippines': 13,\n",
       "  'Poland': 15,\n",
       "  'Portugal': 23,\n",
       "  'Puerto-Rico': 7,\n",
       "  'Scotland': 33,\n",
       "  'South': 6,\n",
       "  'Taiwan': 21,\n",
       "  'Thailand': 18,\n",
       "  'Trinadad&Tobago': 34,\n",
       "  'United-States': 0,\n",
       "  'Vietnam': 37,\n",
       "  'Yugoslavia': 30},\n",
       " 'occupation': {'?': 11,\n",
       "  'Adm-clerical': 0,\n",
       "  'Armed-Forces': 13,\n",
       "  'Craft-repair': 6,\n",
       "  'Exec-managerial': 1,\n",
       "  'Farming-fishing': 8,\n",
       "  'Handlers-cleaners': 2,\n",
       "  'Machine-op-inspct': 9,\n",
       "  'Other-service': 4,\n",
       "  'Priv-house-serv': 14,\n",
       "  'Prof-specialty': 3,\n",
       "  'Protective-serv': 12,\n",
       "  'Sales': 5,\n",
       "  'Tech-support': 10,\n",
       "  'Transport-moving': 7},\n",
       " 'relationship': {'Husband': 1,\n",
       "  'Not-in-family': 0,\n",
       "  'Other-relative': 5,\n",
       "  'Own-child': 3,\n",
       "  'Unmarried': 4,\n",
       "  'Wife': 2},\n",
       " 'workclass': {'?': 5,\n",
       "  'Federal-gov': 3,\n",
       "  'Local-gov': 4,\n",
       "  'Never-worked': 8,\n",
       "  'Private': 2,\n",
       "  'Self-emp-inc': 6,\n",
       "  'Self-emp-not-inc': 1,\n",
       "  'State-gov': 0,\n",
       "  'Without-pay': 7}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_dataset['encoding_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emphasize again that all this is wrapped-up in a function saved in the module `wide_deep.data_utils`. Therefore, as long as your data is in a state similar to the original `DF` at the beginning of this notebook, you will be able to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wide_deep.data_utils import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and simply call the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
