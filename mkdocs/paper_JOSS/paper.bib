@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@misc{joseph2021pytorch,
      title={PyTorch Tabular: A Framework for Deep Learning with Tabular Data},
      author={Manu Joseph},
      year={2021},
      eprint={2104.13638},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{erickson2020autogluon,
  doi = {10.48550/ARXIV.2003.06505},
  url = {https://arxiv.org/abs/2003.06505},
  author = {Erickson, Nick and Mueller, Jonas and Shirkov, Alexander and Zhang, Hang and Larroy, Pedro and Li, Mu and Smola, Alexander},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{singh2020mmf,
  author = {Singh, Amanpreet and Goswami, Vedanuj and Natarajan, Vivek and Jiang, Yu and Chen, Xinlei and Shah, Meet and  Rohrbach, Marcus and Batra, Dhruv and Parikh, Devi},
  title =  {MMF: A multimodal framework for vision and language research},
  howpublished = {\url{https://github.com/facebookresearch/mmf}},
  year = {2020}
}


@misc{chuhan2021fastformer,
  doi = {10.48550/ARXIV.2108.09084},
  url = {https://arxiv.org/abs/2108.09084},
  author = {Wu, Chuhan and Wu, Fangzhao and Qi, Tao and Huang, Yongfeng and Xie, Xing},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Fastformer: Additive Attention Can Be All You Need},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Zero v1.0 Universal}
}


@inproceedings{cheng2016wide,
  doi={10.48550/arXiv.1606.07792},
  title={Wide \& deep learning for recommender systems},
  author={Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and others},
  booktitle={Proceedings of the 1st workshop on deep learning for recommender systems},
  pages={7--10},
  year={2016}
}

@inproceedings{arik2021tabnet,
  title={Tabnet: Attentive interpretable tabular learning},
  author={Arik, Sercan {\"O} and Pfister, Tomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={6679--6687},
  year={2021}
}


@inproceedings{yang2016hierarchical,
author = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
year = {2016},
month = {01},
pages = {1480-1489},
title = {Hierarchical Attention Networks for Document Classification},
doi = {10.18653/v1/N16-1174}
}

@article{huang2020tabtransformer,
  title={Tabtransformer: Tabular data modeling using contextual embeddings},
  author={Huang, Xin and Khetan, Ashish and Cvitkovic, Milan and Karnin, Zohar},
  journal={arXiv preprint arXiv:2012.06678},
  year={2020}
}

@article{somepalli2021saint,
  title={Saint: Improved neural networks for tabular data via row attention and contrastive pre-training},
  author={Somepalli, Gowthami and Goldblum, Micah and Schwarzschild, Avi and Bruss, C Bayan and Goldstein, Tom},
  journal={arXiv preprint arXiv:2106.01342},
  year={2021}
}

@article{gorishniy2021revisiting,
  title={Revisiting deep learning models for tabular data},
  author={Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18932--18943},
  year={2021}
}

@article{wu2021fastformer,
  title={Fastformer: Additive attention can be all you need},
  author={Wu, Chuhan and Wu, Fangzhao and Qi, Tao and Huang, Yongfeng and Xie, Xing},
  journal={arXiv preprint arXiv:2108.09084},
  year={2021}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}

@inproceedings{blundell2015weight,
  title={Weight uncertainty in neural network},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1613--1622},
  year={2015},
  organization={PMLR}
}

@inproceedings{he2016deep,
  doi= {10.1109/cvpr.2016.90},
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{zhang2018shufflenet,
  doi={10.1109/CVPR.2018.00716},
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{xie2017aggregated,
  doi={10.1109/CVPR.2017.634},
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@article{zagoruyko2016wide,
  doi={10.5244/c.30.87},
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{xu2022regnet,
  doi={10.1109/TNNLS.2022.3158966},
  title={RegNet: self-regulated network for image classification},
  author={Xu, Jing and Pan, Yu and Pan, Xinglin and Hoi, Steven and Yi, Zhang and Xu, Zenglin},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2022},
  publisher={IEEE}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{tan2019mnasnet,
  doi={10.1109/CVPR.2019.00293},
  title={Mnasnet: Platform-aware neural architecture search for mobile},
  author={Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2820--2828},
  year={2019}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@article{iandola2016squeezenet,
  title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}

@article{hochreiter1997lstm,
author = {Hochreiter, Sepp and Schmidhuber, JÃ¼rgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}

@article{cho2014properties,
  doi={10.3115/v1/w14-4012},
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@inproceedings{yang2021delving,
  title={Delving into deep imbalanced regression},
  author={Yang, Yuzhe and Zha, Kaiwen and Chen, Yingcong and Wang, Hao and Katabi, Dina},
  booktitle={International Conference on Machine Learning},
  pages={11842--11851},
  year={2021},
  organization={PMLR}
}

@article{wang2019deep,
  title={A deep probabilistic model for customer lifetime value prediction},
  author={Wang, Xiaojing and Liu, Tianqi and Miao, Jingang},
  journal={arXiv preprint arXiv:1912.07753},
  year={2019}
}

@article{gorishniy2022embeddings,
  title={On Embeddings for Numerical Features in Tabular Deep Learning},
  author={Gorishniy, Yura and Rubachev, Ivan and Babenko, Artem},
  journal={arXiv preprint arXiv:2203.05556},
  year={2022}
}

@manual{pytorch_widedeep_examples,
  title={pytorch-widedeep examples},
  note="[Online]. Available at: https://github.com/jrzaurin/pytorch-widedeep/tree/master/examples"
}

@manual{torchvision_models,
  title={torchvision models},
  note="[Online]. Available at: https://pytorch.org/vision/stable/models.html"
}

@manual{torchvision_weight,
  title={torchvision multi weight support},
  note="[Online]. Available at: https://pytorch.org/blog/introducing-torchvision-new-multi-weight-support-api/"
}

@manual{torch_sample,
  title={torch sample},
  note="[Online]. Available at: https://github.com/ncullen93/torchsample"
}

@manual{keras,
  title={keras},
  note="[Online]. Available at: https://keras.io/"
}

@manual{fastai_tokenizer,
  title={fastai tokenizer},
  note="[Online]. Available at: https://docs.fast.ai/text.transform.html#BaseTokenizer.tokenizer"
}

@manual{dl4cv,
  title={dl4cv},
  note="[Online]. Available at: https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/"
}

@manual{pytorch_widedeep_slack,
  title={pytorch-widedeep slack},
  note="[Online]. Available at: https://join.slack.com/t/pytorch-widedeep/shared_invite/zt-soss7stf-iXpVuLeKZz8lGTnxxtHtTw"
}

@inproceedings{garg2022multimodality,
  title={Multimodality for NLP-Centered Applications: Resources, Advances and Frontiers},
  author={Garg, Muskan and Wazarkar, Seema and Singh, Muskaan and Bojar, Ond{\v{r}}ej},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={6837--6847},
  year={2022}
}

@incollection{wang2017deep,
 	doi={10.48550/arXiv.1708.05123},
  title={Deep \& cross network for ad click predictions},
  author={Wang, Ruoxi and Fu, Bin and Fu, Gang and Wang, Mingliang},
  booktitle={Proceedings of the ADKDD'17},
  pages={1--7},
  year={2017}
}